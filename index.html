<!DOCTYPE HTML>
<html class="no-js">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <title>HLA-Face</title>
    <meta name="description" content="Lithium Description" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <link href="css/plugins.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/application.css" media="screen" rel="stylesheet" type="text/css" />
  </head>

<body>

    <!-- ABOUT -->

    <section id="page-about" class="section">
      <div align="center" style="padding-bottom: 100px;">
        <p class="copy-02">TPAMI 2022</p>
        <p class="heading h-01">Unsupervised Face Detection in the Dark</p>

        <p class="copy-02">
          <a href="https://daooshee.github.io/website/">Wenjing Wang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://nevermore808.github.io/">Xinhao Wang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://flyywh.github.io/">Wenhan Yang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
        </p>
      </div>

      <div class="site-inner">
        <h3 class="heading h-03">Abstract</h3>
            <p class="copy-02">Low-light face detection is challenging but critical for real-world applications, such as nighttime autonomous driving and city surveillance. Current face detection models rely on extensive annotations and lack generality and flexibility. In this paper, we explore how to learn face detectors without low-light annotations. Fully exploiting existing normal light data, we propose adapting face detectors from normal light to low light. This task is difficult because the gap between brightness and darkness is too large and complicated at the object level and pixel level. Accordingly, the performance of current low-light enhancement or adaptation methods is unsatisfactory. To solve this problem, we propose a joint High-Low Adaptation (HLA) framework. We design bidirectional low-level adaptation and multitask high-level adaptation. For low-level, we enhance the dark images and degrade the normal-light images, making both domains move toward each other. For high-level, we combine context-based and contrastive learning to comprehensively close the features on different domains. Experiments show that our HLA-Face v2 model obtains superior low-light face detection performance even without the use of low-light annotations. Moreover, our adaptation scheme can be extended to a wide range of applications, such as improving supervised learning and generic object detection.</p>
      </div>

<!--       <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Method</h3>
        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="motivation.jpg" width=90%> <br>
        </div>

        <p class='copy-02'>Motivation: comparison of different adaptive low light detection techniques. L: low light data. H: normal light data. Existing enhancement-based, darkening-based, and feature adaptation methods either ignore the high-level gap, or have limited effects due to the huge and complex gap between L and H. Our method instead considers both low-level and high-level adaptation, therefore achieves better performance.
        </p>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="framework_2.jpg" width=70%> <br>
        </div>

        <p class='copy-02'>Framework: <a style="color:#4C6E8B"><b>LOW-LEVEL</b></a> adaptation fills the gap by creating intermediate states. We bidirectionally brighten the low light data as well as distort the normal light data with noise and color bias. Based on the built intermediate states, we use multi-task cross-domain self-supervised learning to fill the <a style="color:#85937E"><b>HIGH-LEVEL</b></a> gap.
        </p>
      </div> -->

<!--       <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Selected Experimental Results</h3>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="comp_map.jpg" width=60%> <br>
        </div>

        <div align="center">
          <p class='copy-02'>Precision-Recall (PR) curves on DARK FACE.
          </p>
        </div>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="enh_comp.jpg" width=90%> <br>
        </div>



        <p class='copy-02'>Qualitative comparison of different enhancement-based methods. (a) Input low light image and the ground truth boxes. (b)-(g) Results of low-light enhancement methods with DSFD [1]. (h) Our result.
        </p>

      </div>
 -->


      <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <ul style="line-height:1.5; padding-left: 50px; padding-right: 50px">
          　　<li class="copy-02"> Paper: Coming Soon
            <!-- <a href="https://arxiv.org/abs/2104.01984">arXiv</a></li> -->
          　　<li class="copy-02"> Code: Coming Soon
            <!-- <a href="https://github.com/daooshee/HLA-Face-Code">Github</a></li> -->
          　　<li class="copy-02"> Supplementary Material: Coming Soon
            <!-- <a href="https://github.com/daooshee/HLA-Face-Code/blob/main/Supplementary%20Material.pdf">PDF</a></li> -->
          </ul>
      </div>
      

<!--       <div class="site-inner" style="padding-top:50px;">
        <p class='heading h-03'> Citation</p>
        <p class="copy-02"> @InProceedings{HLAFace_2021_CVPR, <br>
        &nbsp; &nbsp; author = {Wang, Wenjing and Yang, Wenhan and Liu, Jiaying}, <br>
        &nbsp; &nbsp; title = {HLA-Face: Joint High-Low Adaptation for Low Light Face Detection}, <br>
        &nbsp; &nbsp; booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, <br>
        &nbsp; &nbsp; month = {June}, <br>
        &nbsp; &nbsp; year = {2021} <br>
        } <br> 
        </p>
      </div>
 -->
<!--       <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <p class="copy-02"> [1] Jian Li, Yabiao Wang, Changan Wang, Ying Tai, Jianjun Qian, Jian Yang, Chengjie Wang, Jilin Li, Feiyue Huang: DSFD: Dual Shot Face Detector. CVPR 2019: 5060-5069</p>
          <br>
          <p class="copy-02"> [2] Xiaojie Guo, Yu Li, Haibin Ling: LIME: Low-Light Image Enhancement via Illumination Map Estimation. IEEE Trans. Image Process. 26(2): 982-993 (2017)</p>
      </div>
 -->
    <section id="page-about" class="section">

</body>
</html>
